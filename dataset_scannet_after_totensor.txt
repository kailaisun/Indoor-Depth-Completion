dataset.shape
torch.Size([24616, 3, 224, 224])
torch.max(dataset)
tensor(1.)
torch.min(dataset)
tensor(0.)
da
Traceback (most recent call last):
  File "<string>", line 1, in <module>
NameError: name 'da' is not defined
data
Traceback (most recent call last):
  File "<string>", line 1, in <module>
NameError: name 'data' is not defined
dataset[0]
tensor([[[1.0000, 1.0000, 0.3490,  ..., 1.0000, 1.0000, 1.0000],
         [1.0000, 1.0000, 0.5216,  ..., 1.0000, 1.0000, 1.0000],
         [1.0000, 1.0000, 0.8667,  ..., 1.0000, 1.0000, 1.0000],
         ...,
         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.5451, 0.0235],
         [1.0000, 1.0000, 1.0000,  ..., 0.9216, 0.0627, 0.0000],
         [1.0000, 1.0000, 1.0000,  ..., 0.3333, 0.0000, 0.0000]],

        [[1.0000, 1.0000, 0.3490,  ..., 1.0000, 1.0000, 1.0000],
         [1.0000, 1.0000, 0.5216,  ..., 1.0000, 1.0000, 1.0000],
         [1.0000, 1.0000, 0.8667,  ..., 1.0000, 1.0000, 1.0000],
         ...,
         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.5451, 0.0235],
         [1.0000, 1.0000, 1.0000,  ..., 0.9216, 0.0627, 0.0000],
         [1.0000, 1.0000, 1.0000,  ..., 0.3333, 0.0000, 0.0000]],

        [[1.0000, 1.0000, 0.3490,  ..., 1.0000, 1.0000, 1.0000],
         [1.0000, 1.0000, 0.5216,  ..., 1.0000, 1.0000, 1.0000],
         [1.0000, 1.0000, 0.8667,  ..., 1.0000, 1.0000, 1.0000],
         ...,
         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.5451, 0.0235],
         [1.0000, 1.0000, 1.0000,  ..., 0.9216, 0.0627, 0.0000],
         [1.0000, 1.0000, 1.0000,  ..., 0.3333, 0.0000, 0.0000]]])
torch.var(dataset)
Evaluating: torch.var(dataset) did not finish after 3.00 seconds.
This may mean a number of things:
- This evaluation is really slow and this is expected.
    In this case it's possible to silence this error by raising the timeout, setting the
    PYDEVD_WARN_EVALUATION_TIMEOUT environment variable to a bigger value.

- The evaluation may need other threads running while it's running:
    In this case, it's possible to set the PYDEVD_UNBLOCK_THREADS_TIMEOUT
    environment variable so that if after a given timeout an evaluation doesn't finish,
    other threads are unblocked or you can manually resume all threads.

    Alternatively, it's also possible to skip breaking on a particular thread by setting a
    `pydev_do_not_trace = True` attribute in the related threading.Thread instance
    (if some thread should always be running and no breakpoints are expected to be hit in it).

- The evaluation is deadlocked:
    In this case you may set the PYDEVD_THREAD_DUMP_ON_WARN_EVALUATION_TIMEOUT
    environment variable to true so that a thread dump is shown along with this message and
    optionally, set the PYDEVD_INTERRUPT_THREAD_TIMEOUT to some value so that the debugger
    tries to interrupt the evaluation (if possible) when this happens.
tensor(0.0576)
torch.mean(dataset)
tensor(0.9330)
